{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python test of the logistic regresion algorithm-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--files FILES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/louisdussart/Library/Jupyter/runtime/kernel-6648c667-ae4b-4d88-a95e-1dda76af466e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louisdussart/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from log_reg import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self=self\n",
    "    \n",
    "    def __cleaning(self,path,column,dataset):\n",
    "        data = pd.read_csv(path)\n",
    "        if (dataset == 'test'): \n",
    "            data = data.drop(['Index',str(column)], axis=1)        \n",
    "            final_data = data.dropna().reset_index(drop=True)\n",
    "        else:\n",
    "            data = data.dropna().reset_index(drop=True)\n",
    "            data = data.drop(['Index'], axis=1)\n",
    "            spread = pd.get_dummies(data[str(column)])\n",
    "            final_data = pd.concat([data, spread], axis=1)\n",
    "        return final_data\n",
    "    \n",
    "    def __minimum(self,frame):\n",
    "        m = frame.iloc[0]\n",
    "        for i in np.arange(1, len(frame)):\n",
    "            if (m > frame.iloc[i]): m = frame.iloc[i]\n",
    "        return m\n",
    "    \n",
    "    def __maximum(self,frame):\n",
    "        m = frame.iloc[0]\n",
    "        for i in np.arange(1, len(frame)):\n",
    "            if (m < frame.iloc[i]): m = frame.iloc[i]\n",
    "        return m\n",
    "    \n",
    "    def __selection(self,data):\n",
    "        inter = data._get_numeric_data()\n",
    "        final_data = pd.DataFrame(index=data.index)\n",
    "        for column in list(inter.columns):\n",
    "            final_data[column] = (inter[column] - self.__minimum(inter[column]))/(self.__maximum(inter[column]) - self.__minimum(inter[column]))\n",
    "        return final_data\n",
    "    \n",
    "    def __add_intercept(self,data):\n",
    "        cols = data.columns\n",
    "        data['Intercept'] = 1\n",
    "        return data.filter(['Intercept'] + list(cols))\n",
    "        \n",
    "    def preprocess(self,path,column,dataset):\n",
    "        data = self.__cleaning(path, column,dataset)\n",
    "        inter_data = self.__selection(data)\n",
    "        final_data = self.__add_intercept(inter_data)\n",
    "        return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(path1, path2, output_column,dataset):\n",
    "    pre = preprocess()\n",
    "    data = pre.preprocess(path1, output_column,dataset)\n",
    "    \n",
    "    weights = pd.read_csv(path2)\n",
    "    weights = weights.drop(weights.columns[0], axis=1)\n",
    "    \n",
    "    predictions = {}\n",
    "    results = pd.DataFrame(index=data.index)\n",
    "    for weight in weights.columns:\n",
    "        predictions[weight] = pd.DataFrame(sigmoid(np.dot(data,weights[weight])))\n",
    "        results = pd.concat([results, predictions[weight]], axis=1)\n",
    "    \n",
    "    results.columns = ['Gryffindor', 'Slytherin', 'Ravenclaw', 'Hufflepuff']\n",
    "    \n",
    "    final_results = pd.DataFrame(results.idxmax(axis=1))\n",
    "    final_results.columns = ['New students houses']\n",
    "    final_results.to_csv('houses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(path1='dataset_test.csv', \n",
    "           path2='logreg_weights.csv', \n",
    "           output_column='Hogwarts House', \n",
    "           dataset='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
